{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask generation with image coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input image and the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "input_path = '../inputs/inpainting/beach.png'\n",
    "input_image = Image.open(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(input_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_input_text = \"200, 300; 480, 290\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_points = None\n",
    "\n",
    "if coord_input_text is not None:\n",
    "    try:\n",
    "        points = coord_input_text.split(';')\n",
    "        input_points = []\n",
    "        for point in points:\n",
    "            x, y = map(int, point.split(',')) # Split by comma to get x and y coordinates\n",
    "            input_points.append([x, y])\n",
    "        input_points = [input_points] # Wrap input_points in another list to match the expected format e.g. [[[515,575],[803,558],[1684,841]]]\n",
    "    except ValueError:\n",
    "        print(\"Invalid input format for coordinates (expected: x1,y1;x2,y2;x3,y3)\")\n",
    "        input_points = None\n",
    "\n",
    "input_image = input_image.convert(\"RGB\")\n",
    "print('input points:', input_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Display the image\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(input_image)\n",
    "\n",
    "# Draw points on the image\n",
    "for x, y in input_points[0]:\n",
    "    ellipse = patches.Ellipse((x, y), width=10, height=10, edgecolor='red', facecolor='red')\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "# Hide the axis\n",
    "ax.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the SAM model (use facebook/sam-vit-base checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import SamModel, SamProcessor\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('device:', device)\n",
    "model = SamModel.from_pretrained(\"facebook/sam-vit-base\").to(device)\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer the model and select the mask with the highest IoU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = processor(input_image, input_points=input_points, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "masks = processor.image_processor.post_process_masks(\n",
    "    outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu()\n",
    ")\n",
    "scores = outputs.iou_scores\n",
    "masks = masks[0].squeeze(0)\n",
    "max_index = torch.argmax(scores)\n",
    "best_mask = masks[max_index]\n",
    "    \n",
    "output = best_mask\n",
    "\n",
    "image_array = np.where(output, 255, 0).astype(np.uint8)\n",
    "mask_image = Image.fromarray(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the output mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(input_image)\n",
    "axs[0].axis('off')  # Hide the axis\n",
    "axs[0].set_title('Original image')  # Optionally set a title\n",
    "\n",
    "# Display the second image in the right subplot\n",
    "axs[1].imshow(mask_image)\n",
    "axs[1].axis('off')  # Hide the axis\n",
    "axs[1].set_title('Mask image')  # Optionally set a title\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-editing-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
