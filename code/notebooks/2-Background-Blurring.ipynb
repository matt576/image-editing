{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background blurring in portrait mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook introduces background blurring for input images. This function allows for blurring the selected areas of the image, based on the estimated depth from the Depth-Anything model. The implementation allows for use of given masks, as well as automatic foregound mask generation using the RMBG-1.4 model. In this notebook, we will provide a step-by-step guide to blurring the image using foreground masking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "input_path = '../inputs/background-blurring/photographer.png'\n",
    "input_image = Image.open(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(input_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the blur and sharpen parameters of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = 15\n",
    "sharpen = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "input_image = input_image.convert(\"RGB\")\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(current_dir), '..'))\n",
    "sys.path.append(os.path.join(parent_dir, 'code'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the RMBG-1.4 model for foreground extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageSegmentation\n",
    "import torch\n",
    "\n",
    "model = AutoModelForImageSegmentation.from_pretrained(\"briaai/RMBG-1.4\",trust_remote_code=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer the model and extract the foreground element from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_foreground import preprocess_image, postprocess_image\n",
    "from scipy.ndimage import label, find_objects\n",
    "import numpy as np\n",
    "\n",
    "# set the values for model size and images of how much percent of whole image should be dismissed\n",
    "model_size = (1024, 1024)\n",
    "img_percent = 0.05\n",
    "\n",
    "if img_percent < 0.0 or img_percent > 1.0:\n",
    "    raise ValueError('The img_percent variable should be in the range (0.0, 1.0)')\n",
    "\n",
    "dismissed_pixels = img_percent * model_size[0] * model_size[1]\n",
    "\n",
    "# prepare input\n",
    "input_image_size = np.array(input_image).shape[:2]\n",
    "input_image_resized = input_image.resize(model_size)\n",
    "\n",
    "orig_im = np.array(input_image_resized)\n",
    "orig_im_size = orig_im.shape[0:2]\n",
    "model_input_size = model_size\n",
    "image = preprocess_image(orig_im, model_input_size).to(device)\n",
    "\n",
    "# inference \n",
    "result = model(image)\n",
    "\n",
    "# post process\n",
    "result_image = postprocess_image(result[0][0], orig_im_size)\n",
    "\n",
    "# save result\n",
    "pil_im = Image.fromarray(result_image)\n",
    "no_bg_image = Image.new(\"RGBA\", pil_im.size, (0,0,0,0))\n",
    "\n",
    "# remove small groups of foreground map\n",
    "np_im = np.array(pil_im)\n",
    "np_im[np_im > 0] = 1\n",
    "labeled_array, num_features = label(np_im)\n",
    "objects = find_objects(labeled_array)\n",
    "for i, obj_slice in enumerate(objects):\n",
    "    if np.sum(labeled_array[obj_slice] == (i + 1)) < dismissed_pixels:      # The whole image has 1024x1024 ~ 10^6 pixels\n",
    "        np_im[labeled_array == (i + 1)] = 0\n",
    "masked_im = np_im * np.array(pil_im)\n",
    "cleaned_pil_im = Image.fromarray(masked_im)\n",
    "\n",
    "# apply the mask\n",
    "no_bg_image.paste(input_image_resized, mask=cleaned_pil_im)\n",
    "no_bg_image = no_bg_image.resize((input_image_size[1], input_image_size[0]))\n",
    "\n",
    "foreground_image = no_bg_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the foreground element in a form of mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(foreground_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the depth-based blur to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blur_image import apply_blur\n",
    "\n",
    "blurred_image = apply_blur(input_image, foreground_image, blur, sharpen, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visusalise the blurred image, solely based on the depth measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(blurred_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste the original foreground on top of the blurred image to increase the visual quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image.paste(foreground_image, foreground_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(blurred_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(input_image)\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original image')\n",
    "\n",
    "# Display the second image in the right subplot\n",
    "axs[1].imshow(blurred_image)\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Blurred image')\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-editing-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
